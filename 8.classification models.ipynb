{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "uBTJdWfVyX20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePljYRrcx-JT"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML Concordia/Major Assignment 2/archive/survey lung cancer.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_num = dataframe\n",
        "replacement_map = {'M': 1, 'F': 0}\n",
        "dataframe_num['GENDER'] = dataframe_num['GENDER'].replace(replacement_map)\n",
        "dataframe_num = dataframe\n",
        "replacement_map = {'YES': 1, 'NO': 0}\n",
        "dataframe_num['LUNG_CANCER'] = dataframe_num['LUNG_CANCER'].replace(replacement_map)"
      ],
      "metadata": {
        "id": "AuOM_Ur4zJmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_x = dataframe_num[dataframe_num.columns.difference(['LUNG_CANCER'])]\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataframe_x, dataframe_num['LUNG_CANCER'], test_size=0.3)"
      ],
      "metadata": {
        "id": "IPi1tpbNz2em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-nearest\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=10)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = knn_model.predict(X_train)\n",
        "test_predictions = knn_model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report for Training Set:\")\n",
        "print(classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"\\nClassification Report for Testing Set:\")\n",
        "print(classification_report(y_test, test_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DWzJ3zO3ftQ",
        "outputId": "792d46f0-e659-457e-d406-193a136f5599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.04      0.08        23\n",
            "           1       0.90      0.99      0.94       193\n",
            "\n",
            "    accuracy                           0.89       216\n",
            "   macro avg       0.70      0.52      0.51       216\n",
            "weighted avg       0.85      0.89      0.85       216\n",
            "\n",
            "\n",
            "Classification Report for Testing Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.12      0.21        16\n",
            "           1       0.84      0.99      0.91        77\n",
            "\n",
            "    accuracy                           0.84        93\n",
            "   macro avg       0.76      0.56      0.56        93\n",
            "weighted avg       0.81      0.84      0.79        93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = svm_model.predict(X_train)\n",
        "test_predictions = svm_model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report for Training Set:\")\n",
        "print(classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"\\nClassification Report for Testing Set:\")\n",
        "print(classification_report(y_test, test_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng_57r7Vyxvt",
        "outputId": "71068bf4-f550-4d88-c844-11234b4eb1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77        23\n",
            "           1       0.97      0.97      0.97       193\n",
            "\n",
            "    accuracy                           0.95       216\n",
            "   macro avg       0.86      0.88      0.87       216\n",
            "weighted avg       0.95      0.95      0.95       216\n",
            "\n",
            "\n",
            "Classification Report for Testing Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.56      0.64        16\n",
            "           1       0.91      0.96      0.94        77\n",
            "\n",
            "    accuracy                           0.89        93\n",
            "   macro avg       0.83      0.76      0.79        93\n",
            "weighted avg       0.89      0.89      0.89        93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = gnb_model.predict(X_train)\n",
        "test_predictions = gnb_model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report for Training Set:\")\n",
        "print(classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"\\nClassification Report for Testing Set:\")\n",
        "print(classification_report(y_test, test_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLL-BNwt16S1",
        "outputId": "15f84110-2534-45ed-9de5-0298dfa1165e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.65      0.61        23\n",
            "           1       0.96      0.94      0.95       193\n",
            "\n",
            "    accuracy                           0.91       216\n",
            "   macro avg       0.77      0.80      0.78       216\n",
            "weighted avg       0.92      0.91      0.91       216\n",
            "\n",
            "\n",
            "Classification Report for Testing Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.56      0.64        16\n",
            "           1       0.91      0.96      0.94        77\n",
            "\n",
            "    accuracy                           0.89        93\n",
            "   macro avg       0.83      0.76      0.79        93\n",
            "weighted avg       0.89      0.89      0.89        93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_model = DecisionTreeClassifier()\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = tree_model.predict(X_train)\n",
        "test_predictions = tree_model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report for Training Set:\")\n",
        "print(classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"\\nClassification Report for Testing Set:\")\n",
        "print(classification_report(y_test, test_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIAxcvco295C",
        "outputId": "0da9081b-8cb5-4f80-8232-c8f8603a2b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        23\n",
            "           1       1.00      1.00      1.00       193\n",
            "\n",
            "    accuracy                           1.00       216\n",
            "   macro avg       1.00      1.00      1.00       216\n",
            "weighted avg       1.00      1.00      1.00       216\n",
            "\n",
            "\n",
            "Classification Report for Testing Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.31      0.42        16\n",
            "           1       0.87      0.96      0.91        77\n",
            "\n",
            "    accuracy                           0.85        93\n",
            "   macro avg       0.75      0.64      0.67        93\n",
            "weighted avg       0.83      0.85      0.83        93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AdaBoost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "adaboost_model = AdaBoostClassifier()\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = adaboost_model.predict(X_train)\n",
        "test_predictions = adaboost_model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report for Training Set:\")\n",
        "print(classification_report(y_train, train_predictions))\n",
        "\n",
        "print(\"\\nClassification Report for Testing Set:\")\n",
        "print(classification_report(y_test, test_predictions))\n",
        "\n",
        "print('''By default, the AdaBoostClassifier utilizes a decision tree with a maximum depth of 1 (max_depth=1), commonly referred to as a decision stump, as its base estimator.\n",
        "This decision stump represents a simple tree model comprising a single decision node and two leaf nodes''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSrnQKE-3NfC",
        "outputId": "c956b073-0423-44bd-f812-dc887a5a7a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82        23\n",
            "           1       0.97      0.98      0.98       193\n",
            "\n",
            "    accuracy                           0.96       216\n",
            "   macro avg       0.92      0.88      0.90       216\n",
            "weighted avg       0.96      0.96      0.96       216\n",
            "\n",
            "\n",
            "Classification Report for Testing Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.31      0.42        16\n",
            "           1       0.87      0.96      0.91        77\n",
            "\n",
            "    accuracy                           0.85        93\n",
            "   macro avg       0.75      0.64      0.67        93\n",
            "weighted avg       0.83      0.85      0.83        93\n",
            "\n",
            "By default, the AdaBoostClassifier utilizes a decision tree with a maximum depth of 1 (max_depth=1), commonly referred to as a decision stump, as its base estimator. \n",
            "This decision stump represents a simple tree model comprising a single decision node and two leaf nodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Discuss and compare the performance of the trained models.\n",
        "The K-nearest model with K=10 has the worst performance, especially in predicting no-cancer dataset. As the report shows, the accuracy of the model is around 50% while the accuracy for predicting cancer is over 90%. This bad forecast does not have much effect on the final accuracy because the number of healthy items is very small. As a result, the report shows an accuracy of prediction around 80-90%.\n",
        "\n",
        "The SVM and GaussianNB are similar in the accuracy of predictions. They have a high accuracy in training and testing sets. To explain more, SVM has a high accuracy in predicting cancer and acceptable accuracy in predicting no-cancer.  GaussianNB has a similarly high accuracy in the prediction of cancer. While the prediction of no-cancer is less than the same situation in SVM. Finally, the accuracy of both of them is around 90%.\n",
        "\n",
        "Overfitting occurred in the decision tree. The decision tree correctly predicts all data sets in training, while the prediction accuracy is lower in the testing set. The precision of prediction in the testing set is around 60% in no-cancer and more than 90% in cancer situations. Finally, the accuracy of the testing set is 85%.\n",
        "\n",
        "AdaBoost predicts cancer and no-cancer of training datasets with a precision of 80-90%, in both situations. The accuracy of prediction of the training dataset is 96%. While the precision for testing dataset is a little different. The precision of predicting cancer and no cancer are around 87% and 62%, respectively. Finally, the accuracy of prediction of testing data is 85%."
      ],
      "metadata": {
        "id": "JAqsQSFprug2"
      }
    }
  ]
}